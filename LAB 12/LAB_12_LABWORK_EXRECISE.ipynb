{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu8ReESnioME8NjVfv6zLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vatsalvasani/CE155_VATSAL_VASANI_ML_LABS/blob/main/LAB%2012/LAB_12_LABWORK_EXRECISE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LAB 12 : LABWORK AND EXRERCISE**"
      ],
      "metadata": {
        "id": "0kvtGG91Y4b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step Involve In Creating Model :**\n",
        "1) Load MNIST Dataset\n",
        "\n",
        "2) Preprocessing Dataset\n",
        "\n",
        "3) Create DataLoader\n",
        "\n",
        "4) Create ANN Model With One Hideen Layer\n",
        "\n",
        "5) Define Criterion As EL And Optimizer As SGD\n",
        "\n",
        "6) Train Model\n",
        "\n",
        "7) Predict Digit"
      ],
      "metadata": {
        "id": "Qog3VNamr0N9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "pgGNEy2iYWra",
        "outputId": "7507014e-e03c-428b-a046-0c8a59a5c034"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_epochs :  5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-cfa1bc57bb2c>:55: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  trainset=np.array(list(zip(X_train,y_train)))\n",
            "<ipython-input-3-cfa1bc57bb2c>:55: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  trainset=np.array(list(zip(X_train,y_train)))\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "  flatten_data=[]\n",
        "  for i in range(len(X_data)):\n",
        "    sample=X_data[i]\n",
        "    flatten_row=[]\n",
        "    for row in sample:\n",
        "      flatten_row+=list(row)\n",
        "      pass\n",
        "    pass\n",
        "    flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    pass\n",
        "  return np.array(flatten_data)\n",
        "  pass\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:100]\n",
        "y_train=y_train[0:100]\n",
        "\n",
        "# visualize one of the images in data set\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "\n",
        "y_train=torch.tensor(y_train)\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 5000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"num_epochs : \",num_epochs)\n",
        "trainset=np.array(list(zip(X_train,y_train)))\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE**"
      ],
      "metadata": {
        "id": "s2D36-Lqwj9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "    flatten_data=[]\n",
        "    for i in range(len(X_data)):\n",
        "        sample=X_data[i]\n",
        "        flatten_row=[]\n",
        "        for row in sample:\n",
        "            flatten_row+=list(row)\n",
        "        flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    return np.array(flatten_data)\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def predict(self,x):\n",
        "        output=self.forward(x).tolist()[0]\n",
        "        lbl=output.index(max(output))\n",
        "        return lbl\n",
        "        pass\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:200]\n",
        "y_train=y_train[0:200]\n",
        "\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "y_train=torch.tensor(y_train)\n",
        "\n",
        "print(y_train[0])\n",
        "\n",
        "batch_size = 10\n",
        "n_iters = 5000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"Number Of Epochs : \",num_epochs)\n",
        "trainset=TensorDataset(X_train,y_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    inputs = Variable(images.view(-1, input_dim))\n",
        "    labels = Variable(labels)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    pass\n",
        "  pass\n",
        "\n",
        "\n",
        "sample=torch.tensor(flatten([sample_image_mat]))\n",
        "print(\"prediction :\",model.predict(sample))\n",
        "# y_pred=torch.tensor(model.predict(X_test))\n",
        "# print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "rlSUXKcdnWxf",
        "outputId": "71d12522-f055-4d30-f6c1-a8719e34373e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5, dtype=torch.uint8)\n",
            "Number Of Epochs :  250\n",
            "prediction : 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---> Q4 Of Exercise"
      ],
      "metadata": {
        "id": "lDv7BhilwoVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "    flatten_data=[]\n",
        "    for i in range(len(X_data)):\n",
        "        sample=X_data[i]\n",
        "        flatten_row=[]\n",
        "        for row in sample:\n",
        "            flatten_row+=list(row)\n",
        "        flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    return np.array(flatten_data)\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1,hidden_dim2, output_dim):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def predict(self,x):\n",
        "        \n",
        "        output=self.forward(x).tolist()\n",
        "        output_labels=[]\n",
        "        for elem in output : \n",
        "          lbl=elem.index(max(elem))\n",
        "          output_labels.append(lbl)\n",
        "        output_labels=np.array(output_labels)\n",
        "        return output_labels\n",
        "        pass\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:100]\n",
        "X_test=X_test[0:100]\n",
        "y_train=y_train[0:100]\n",
        "y_test=y_test[0:100]\n",
        "\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "X_test=flatten(X_test)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "X_test=torch.tensor(X_test)\n",
        "y_train=torch.tensor(y_train)\n",
        "y_test=torch.tensor(y_test)\n",
        "\n",
        "print(y_train[0])\n",
        "\n",
        "batch_size = 10\n",
        "n_iters = 10000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"num_epochs : \",num_epochs)\n",
        "trainset=TensorDataset(X_train,y_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim1 = 10\n",
        "hidden_dim2 = 10\n",
        "output_dim = 10\n",
        "\n",
        "model = ANNModel(input_dim, hidden_dim1,hidden_dim2, output_dim)\n",
        "\n",
        "criterion=nn.MSELoss()\n",
        "\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    inputs = Variable(images.view(-1, input_dim))\n",
        "    labels = Variable(labels)\n",
        "    optimizer.zero_grad()\n",
        "    outputs=model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.step()\n",
        "    pass\n",
        "  pass\n",
        "\n",
        "\n",
        "sample=torch.tensor(flatten([sample_image_mat]))\n",
        "print(model.predict(sample))\n",
        "# y_pred=torch.tensor(model.predict(X_test))\n",
        "# print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "nd97AXoGwu1a",
        "outputId": "f9f8b73a-d156-4b78-867b-250715933fb3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5, dtype=torch.uint8)\n",
            "num_epochs :  1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5]\n"
          ]
        }
      ]
    }
  ]
}