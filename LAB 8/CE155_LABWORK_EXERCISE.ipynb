{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vatsalvasani/CE155_ML/blob/main/LAB%208/CE155_LABWORK_EXERCISE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAB 8"
      ],
      "metadata": {
        "id": "fsshTo_5-_Ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of stacking , with max voting as classification model\n"
      ],
      "metadata": {
        "id": "ZWHGdlLy3vWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvnZwvsM3sRh",
        "outputId": "9479715b-69b8-48a0-cd8d-efd1adabcc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0 1 0 0]\n",
            "accuracy :  0.5714285714285714\n",
            "[[1 0]\n",
            " [3 3]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score   \n",
        "\n",
        "def max_voting(output):\n",
        "  votes={}\n",
        "  for elem in output:\n",
        "    if elem in votes:\n",
        "      votes[elem]+=1\n",
        "    else :\n",
        "      votes[elem]=1\n",
        "  \n",
        "  final_output=-1\n",
        "  max_votes=-1\n",
        "  for elem in votes:\n",
        "    if max_votes<votes[elem]:\n",
        "      max_votes=votes[elem]\n",
        "      final_output=elem\n",
        "      pass\n",
        "    pass\n",
        "  print(votes)\n",
        "  return final_output,max_votes\n",
        "  pass\n",
        "\n",
        "def get_data_set():\n",
        "\n",
        "  weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast','Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']\n",
        "  temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
        "  play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
        "  le=preprocessing.LabelEncoder()\n",
        "  weather_encoded=le.fit_transform(weather)\n",
        "  temp_encoded=le.fit_transform(temp)\n",
        "  play_encoded=le.fit_transform(play)\n",
        "  features=tuple(zip(weather_encoded,temp_encoded))\n",
        "  return features,play_encoded\n",
        "  pass\n",
        "\n",
        "def get_individual_classifiers(x_train,y_train,no_of_models=10):\n",
        "  individual_classifiers=[]\n",
        "  for _ in range(no_of_models):\n",
        "    \n",
        "    new_model=CategoricalNB(alpha=1)\n",
        "    new_model.fit(x_train,y_train)\n",
        "    individual_classifiers.append(new_model)\n",
        "    pass\n",
        "  return individual_classifiers\n",
        "  pass\n",
        "\n",
        "def individual_predict(individual_classifiers,input):\n",
        "  output=[]\n",
        "  for classifier in individual_classifiers:\n",
        "    curr_output=list(classifier.predict(input))\n",
        "    output=output+curr_output\n",
        "    pass\n",
        "  return output\n",
        "  pass\n",
        "\n",
        "def get_meta_classifier(x,y):\n",
        "  individual_classifiers=get_individual_classifiers(x_train,y_train)\n",
        "  output=individual_predict(individual_classifiers,x)\n",
        "  meta_x=output\n",
        "  meta_y=[]\n",
        "  div=len(meta_x)//len(x)\n",
        "  for _ in range(div):\n",
        "    meta_y=meta_y+list(y)\n",
        "  meta_classifier=LogisticRegression(random_state=0).fit(x, y)\n",
        "  return meta_classifier\n",
        "  pass\n",
        "\n",
        "def get_accuracy(y_pred,y_test):\n",
        "  \n",
        "  return accuracy_score(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "\n",
        "x,y=get_data_set()\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=155,test_size=0.50)\n",
        "meta_classifier=get_meta_classifier(x_train,y_train)\n",
        "\n",
        "y_pred=meta_classifier.predict(x_test)\n",
        "print(y_pred)\n",
        "print(\"accuracy : \",get_accuracy(y_pred,y_test))\n",
        "# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n",
        "# print(x_1,y_1)\n",
        "cmat=confusion_matrix(y_test,y_pred)\n",
        "print(cmat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stacking using regression and low diabetes database"
      ],
      "metadata": {
        "id": "t1onSksYHdjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# def max_voting(output):\n",
        "#   votes={}\n",
        "#   for elem in output:\n",
        "#     if elem in votes:\n",
        "#       votes[elem]+=1\n",
        "#     else :\n",
        "#       votes[elem]=1\n",
        "  \n",
        "#   final_output=-1\n",
        "#   max_votes=-1\n",
        "#   for elem in votes:\n",
        "#     if max_votes<votes[elem]:\n",
        "#       max_votes=votes[elem]\n",
        "#       final_output=elem\n",
        "#       pass\n",
        "#     pass\n",
        "#   print(votes)\n",
        "#   return final_output,max_votes\n",
        "#   pass\n",
        "\n",
        "def get_data_set():\n",
        "  import pandas as pd\n",
        "  dataset=load_diabetes()\n",
        "  x=dataset.data\n",
        "  y=dataset.target\n",
        "  return x,y\n",
        "  pass\n",
        "\n",
        "def get_individual_classifiers(x_train,y_train,no_of_models=10):\n",
        "  individual_classifiers=[]\n",
        "  for _ in range(no_of_models):\n",
        "    new_model=LinearRegression()\n",
        "    new_model.fit(x_train,y_train)\n",
        "    individual_classifiers.append(new_model)\n",
        "    pass\n",
        "  return individual_classifiers\n",
        "  pass\n",
        "\n",
        "def individual_predict(individual_classifiers,input):\n",
        "  output=[]\n",
        "  for classifier in individual_classifiers:\n",
        "    curr_output=list(classifier.predict(input))\n",
        "    output=output+curr_output\n",
        "    pass\n",
        "  return output\n",
        "  pass\n",
        "\n",
        "def get_meta_classifier(x,y):\n",
        "  individual_classifiers=get_individual_classifiers(x_train,y_train)\n",
        "  output=individual_predict(individual_classifiers,x)\n",
        "  meta_x=output\n",
        "  meta_y=[]\n",
        "  div=len(meta_x)//len(x)\n",
        "  for _ in range(div):\n",
        "    meta_y=meta_y+list(y)\n",
        "  meta_classifier=LinearRegression().fit(x, y)\n",
        "  return meta_classifier\n",
        "  pass\n",
        "\n",
        "def get_accuracy(y_pred,y_test):\n",
        "  return accuracy_score(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "def get_mse(y_pred,y_test):\n",
        "  return mean_squared_error(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "x,y=get_data_set()\n",
        "# print(x,y)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=155,test_size=0.50)\n",
        "meta_classifier=get_meta_classifier(x_train,y_train)\n",
        "y_pred=meta_classifier.predict(x_test)\n",
        "print(\"mse loss : \",get_mse(y_pred,y_test))\n",
        "# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n",
        "# print(x_1,y_1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5TVM7Q5Hg-V",
        "outputId": "c6848f32-06f0-40fa-c843-5681871b8129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse loss :  3422.0687477258402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaboost classifier"
      ],
      "metadata": {
        "id": "A34pWSkl8BXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def get_data_set():\n",
        "  import pandas as pd\n",
        "  dataset=load_breast_cancer()\n",
        "  x=dataset.data\n",
        "  y=dataset.target\n",
        "  return x,y\n",
        "  pass\n",
        "\n",
        "def get_classifier(x,y):\n",
        "  return AdaBoostClassifier().fit(x,y)\n",
        "\n",
        "def get_accuracy(y_pred,y_test):\n",
        "  return accuracy_score(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "def print_classification_report(y_pred,y_test):\n",
        "  print(\"confusion matrix of addboostclassification\")\n",
        "  cmat=confusion_matrix(y_test,y_pred)\n",
        "  print(cmat)\n",
        "  pass\n",
        "x,y=get_data_set()\n",
        "# print(x,y)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=155,test_size=0.50)\n",
        "classifier=get_classifier(x_train,y_train)\n",
        "y_pred=classifier.predict(x_test)\n",
        "print(\"accuracy : \",get_accuracy(y_pred,y_test))\n",
        "print_classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M1xJhAhL1g6",
        "outputId": "8bbfc65c-436b-4c4c-e7f3-4752147e13e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy :  0.9614035087719298\n",
            "confusion matrix of addboostclassification\n",
            "[[ 90   6]\n",
            " [  5 184]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use StackingClassifier from sklearn to implement the same on cancer dataset. \n",
        "Bagging and RandomForest"
      ],
      "metadata": {
        "id": "WqBBSmVsOefs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "def get_data_set():\n",
        "  import pandas as pd\n",
        "  dataset=load_breast_cancer()\n",
        "  atx=dataset.data\n",
        "  y=dataset.target\n",
        "  return x,y\n",
        "  pass\n",
        "\n",
        "def get_classifier(x,y):\n",
        "  return BaggingClassifier().fit(x,y)\n",
        "\n",
        "def get_accuracy(y_pred,y_test):\n",
        "  return accuracy_score(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "def print_classification_report(y_pred,y_test):\n",
        "  print(\"confusion matrix of bagging on descision tree classifier : \")\n",
        "  cmat=confusion_matrix(y_test,y_pred)\n",
        "  print(cmat)\n",
        "  pass\n",
        "\n",
        "x,y=get_data_set()\n",
        "# print(x,y)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=155,test_size=0.50)\n",
        "classifier=get_classifier(x_train,y_train)\n",
        "y_pred=classifier.predict(x_test)\n",
        "print(\"accuracy : \",get_accuracy(y_pred,y_test))\n",
        "print_classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLk_eGPJOiHH",
        "outputId": "1c8ad4e3-b170-4cbb-e95a-b86a55e32943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy :  0.9438596491228071\n",
            "confusion matrix of bagging on descision tree classifier : \n",
            "[[102  11]\n",
            " [  5 167]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise : Try Adaboost Regression on concrete_data.csv."
      ],
      "metadata": {
        "id": "EkXHPxOoQxu1"
      }
    }
  ]
}